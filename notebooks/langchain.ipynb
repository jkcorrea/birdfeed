{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing w/ LangChain\n",
    "[https://langchain.readthedocs.io/en/latest](https://langchain.readthedocs.io/en/latest)\n",
    "\n",
    "[https://github.com/hwchase17/langchain](https://github.com/hwchase17/langchain)\n",
    "\n",
    "NOTE: Make sure you have `OPENAI_API_KEY` set in your env, you can check that it is set below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext dotenvj\n",
    "%dotenv ../.env\n",
    "import os\n",
    "os.environ.get('OPENAI_API_KEY').startswith('sk-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(\n",
    "  model_name=\"text-ada-001\",\n",
    "  n=1,\n",
    "  temperature=0.9,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.0,\n",
    "  presence_penalty=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.get_num_tokens(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "text_splitter = CharacterTextSplitter()\n",
    "\n",
    "with open('./data/transcripts/jt_overwhelming-situations.txt')  as f:\n",
    "    raw_transcript = f.read()\n",
    "\n",
    "source_chunks = []\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=1024, chunk_overlap=0)\n",
    "for chunk in text_splitter.split_text(raw_transcript):\n",
    "    source_chunks.append(Document(page_content=chunk, chunk_size=1024, chunk_overlap=0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not import chromadb python package. Please it install it with `pip install chromadb`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/notebooks-cpka/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:40\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mopenai\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvectorstores\u001b[39;00m \u001b[39mimport\u001b[39;00m Chroma\n\u001b[0;32m----> 4\u001b[0m search_index \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39;49mfrom_documents(source_chunks, OpenAIEmbeddings())\n",
      "File \u001b[0;32m~/.virtualenvs/notebooks-cpka/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:215\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m    214\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m--> 215\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_texts(\n\u001b[1;32m    216\u001b[0m     texts\u001b[39m=\u001b[39;49mtexts,\n\u001b[1;32m    217\u001b[0m     embedding\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m    218\u001b[0m     metadatas\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[1;32m    219\u001b[0m     ids\u001b[39m=\u001b[39;49mids,\n\u001b[1;32m    220\u001b[0m     collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    221\u001b[0m     persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[1;32m    222\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/notebooks-cpka/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:181\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_texts\u001b[39m(\n\u001b[1;32m    156\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    164\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Chroma:\n\u001b[1;32m    165\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[1;32m    167\u001b[0m \u001b[39m    If a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39m        Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m     chroma_collection \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    182\u001b[0m         collection_name\u001b[39m=\u001b[39;49mcollection_name,\n\u001b[1;32m    183\u001b[0m         embedding_function\u001b[39m=\u001b[39;49membedding,\n\u001b[1;32m    184\u001b[0m         persist_directory\u001b[39m=\u001b[39;49mpersist_directory,\n\u001b[1;32m    185\u001b[0m     )\n\u001b[1;32m    186\u001b[0m     chroma_collection\u001b[39m.\u001b[39madd_texts(texts\u001b[39m=\u001b[39mtexts, metadatas\u001b[39m=\u001b[39mmetadatas, ids\u001b[39m=\u001b[39mids)\n\u001b[1;32m    187\u001b[0m     \u001b[39mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[0;32m~/.virtualenvs/notebooks-cpka/lib/python3.11/site-packages/langchain/vectorstores/chroma.py:43\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[0;34m(self, collection_name, embedding_function, persist_directory)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mchromadb\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     44\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import chromadb python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease it install it with `pip install chromadb`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m     )\n\u001b[1;32m     48\u001b[0m \u001b[39m# TODO: Add support for custom client. For now this is in-memory only.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client_settings \u001b[39m=\u001b[39m chromadb\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mSettings()\n",
      "\u001b[0;31mValueError\u001b[0m: Could not import chromadb python package. Please it install it with `pip install chromadb`."
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "search_index = Chroma.from_documents(source_chunks, OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" This talk explores how to deal with overwhelming situations and emotions by introducing the concept of the masculine container, which is a way of creating a safe space for chaos to exist and thrive. It also explains how this concept can be applied to society, relationships, and internally in one's own mind. It suggests techniques such as setting boundaries, creating a successful routine, and chunking tasks into smaller pieces. It also emphasizes the importance of giving yourself positive options to stay focused and productive, and of allowing yourself to be afraid and taking small steps towards facing the fear.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks-cpka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "246485253e9a6c9f39cb85dc9bfa752a5c7d1b2ce015606278efb37fe3373155"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
